{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import matplotlib.pyplot as plt  # Biblioteca para gerar gráficos\n",
    "import pandas as pd\n",
    "from sklearn import metrics, model_selection\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Set:\n",
    "    def __init__(self, dataset, features, output):\n",
    "        self.dataset = dataset\n",
    "        self.features = features\n",
    "        self.output = output\n",
    "\n",
    "    def get_n(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def get_x(self):\n",
    "        return self.dataset[:, self.features]\n",
    "    \n",
    "    def get_x_apply(self, func):\n",
    "        return func(self.dataset[:, self.features])\n",
    "\n",
    "    def set_x(self, new_x):\n",
    "        self.x = new_x\n",
    "\n",
    "    def get_y(self):\n",
    "        return self.dataset[:, self.output]\n",
    "\n",
    "    def get_X(self, normal_fun=None):\n",
    "        if (normal_fun):\n",
    "            return np.c_[np.ones(self.get_n()), normal_fun(self.get_x())]\n",
    "        else:\n",
    "            return np.c_[np.ones(self.get_n()), self.get_x()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_true_positive(y, y_pred):\n",
    "    return y_pred >= 1 and y >= 1\n",
    "\n",
    "def is_false_positive(y, y_pred):\n",
    "    return y_pred >= 1 and y <= 0\n",
    "\n",
    "def is_true_negative(y, y_pred):\n",
    "    return y_pred <= 0 and y <= 0\n",
    "\n",
    "def is_false_negative(y, y_pred):\n",
    "    return y_pred <= 0 and y >= 1\n",
    "\n",
    "def get_prediction_matrix(y, y_pred):\n",
    "    \"\"\" returns (tp, fp, tn, fn) \"\"\"\n",
    "\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for i, pred in enumerate(y_pred):\n",
    "        tp += 1 if is_true_positive(y[i], pred) else 0\n",
    "        fp += 1 if is_false_positive(y[i], pred) else 0\n",
    "        tn += 1 if is_true_negative(y[i], pred) else 0\n",
    "        fn += 1 if is_false_negative(y[i], pred) else 0\n",
    "    return (tp, fp, tn, fn)\n",
    "\n",
    "def accuracy(y, y_pred):\n",
    "    tp, fp, tn, fn = get_prediction_matrix(y, y_pred)\n",
    "    return (tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "def precision(y, y_pred):\n",
    "    tp, fp, tn, fn = get_prediction_matrix(y, y_pred)\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(y, y_pred):\n",
    "    tp, fp, tn, fn = get_prediction_matrix(y, y_pred)\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def f1_score(y, y_pred):\n",
    "    precision_ = precision(y, y_pred)\n",
    "    recall_ = recall(y, y_pred)\n",
    "    return 2 * (precision_ * recall_) / (precision_ + recall_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_split(array, k = int):\n",
    "    \"\"\"realiza o split dos dados em k-folds\"\"\"\n",
    "    shuffled_data = np.random.permutation(array)\n",
    "    folds = np.array_split(shuffled_data, k)\n",
    "    return folds\n",
    "\n",
    "def k_fold_train_test(folds):\n",
    "    \"\"\"retorna um vetor com as configurações de treino e teste definidas pelo k-fold split\n",
    "\n",
    "    returns (i, train, test)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        train = np.vstack([x for j, x in enumerate(folds) if j != i])\n",
    "        test = fold\n",
    "        results.append((i, train, test))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere o conjunto de dados disponível em **kc2.csv**, organizado em 22 colunas, sendo as 21 primeiras colunas os atributos e a última coluna a saída. Os 21 atributos são referentes à caracterização de códigos-fontes para processamento de dados na NASA. A saída é a indicação de ausência (0) ou existência (1) de defeitos. Maiores detalhes sobre os dados p o dem ser conferidos em https://www.openml.org/d/1063."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('kc2.csv', delimiter=',')\n",
    "np.random.seed(666)\n",
    "folds = k_fold_split(data, 10)\n",
    "features = np.arange(21)\n",
    "output = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Considerando uma validação cruzada em 10 folds, avalie modelos de classificação binária nos dados em questão. Para tanto, use as abordagens abaixo:\n",
    "\n",
    "- **KNN** (escolha k = 1 e k = 5, distância Euclidiana (e Mahalonobis, para a pós-graduação));\n",
    "- **Árvore de decisão** (você pode usar uma implementação já existente com índices de impureza de gini e entropia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation com kNN\n",
      "acurácia: 0.77579826 +/- 0.04814430\n",
      "revocação: 0.45108947 +/- 0.15521950\n",
      "precisão: 0.41541681 +/- 0.15497358\n",
      "f1-score: 0.42191653 +/- 0.13682793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def euclidean_distance(p, q):\n",
    "    return np.abs(np.sqrt(np.sum((p - q)**2)))\n",
    "\n",
    "def mahalanobis_distance(x, u, V):\n",
    "    \"\"\"V: matriz de covariância dos dados de treino\"\"\"\n",
    "    VI = np.linalg.pinv(np.cov(V))\n",
    "    rs = (x - u).T\n",
    "    rs = rs.dot(VI)\n",
    "    rs = rs.dot((x - u))\n",
    "    return np.sqrt(rs)\n",
    "    # y_mu = p - np.mean(q)\n",
    "    # V = np.cov(q)\n",
    "    # inv_covmat = np.linalg.inv(V)\n",
    "    # left = np.dot(y_mu, inv_covmat)\n",
    "    # mahal = np.dot(left, y_mu.T)\n",
    "    # return mahal.diagonal()\n",
    "\n",
    "def kNN(X, y, x_test, y_test, k, distance_func = euclidean_distance):\n",
    "    y_pred = []\n",
    "\n",
    "    # encontrar k padrões mais próximos\n",
    "    for xi in x_test:\n",
    "        distances = []\n",
    "        for j in range(X.shape[0]):\n",
    "            distances.append(euclidean_distance(xi, X[j, :]))\n",
    "            # mu = X.mean(axis=0)\n",
    "            # print(VI)\n",
    "            # distances.append(mahalanobis_distance(xi, X[j, :], X))\n",
    "        distances = np.array(distances)\n",
    "\n",
    "        dist = np.argsort(distances)[:k] \n",
    "        labels = y[dist]\n",
    "\n",
    "        lab = stats.mode(labels) \n",
    "        lab = lab.mode[0]\n",
    "        y_pred.append(lab)\n",
    "\n",
    "    # computar predição com base na ponderação das saidos dos padrões mais próximos\n",
    "    return (y_test, np.array(y_pred))\n",
    "\n",
    "n_folds = 10\n",
    "accuracy_, precision_, recall_, f1_score_ = np.zeros(n_folds), np.zeros(n_folds), np.zeros(n_folds), np.zeros(n_folds)\n",
    "for i, train, test in k_fold_train_test(folds):\n",
    "    train = Set(train, features, output)\n",
    "    test = Set(test, features, output)\n",
    "    y_test, y_pred = kNN(train.get_x(), train.get_y(), test.get_x(), test.get_y(), 1)\n",
    "\n",
    "    accuracy_[i] = (accuracy(y_test, y_pred))\n",
    "    precision_[i] = (precision(y_test, y_pred))\n",
    "    recall_[i] = (recall(y_test, y_pred))\n",
    "    f1_score_[i] = (f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"%i-fold cross validation com %s\" % (n_folds, 'kNN'))\n",
    "print(\"acurácia: %.8f +/- %.8f\" % (accuracy_.mean(), accuracy_.std()))\n",
    "print(\"revocação: %.8f +/- %.8f\" % (precision_.mean(), precision_.std()))\n",
    "print(\"precisão: %.8f +/- %.8f\" % (recall_.mean(), recall_.std()))\n",
    "print(\"f1-score: %.8f +/- %.8f\" % (f1_score_.mean(), f1_score_.std()))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20264/2139746010.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprecision_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mrecall_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mf1_score_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%i-fold cross validation com %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'kNN'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20264/557128859.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y, y_pred)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mprecision_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mrecall_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprecision_\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrecall_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprecision_\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrecall_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "accuracy_, precision_, recall_, f1_score_ = np.zeros(n_folds), np.zeros(n_folds), np.zeros(n_folds), np.zeros(n_folds)\n",
    "for i, train, test in k_fold_train_test(folds):\n",
    "    train = Set(train, features, output)\n",
    "    test = Set(test, features, output)\n",
    "    # neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "    VI = np.linalg.pinv(np.cov(train.get_x()))\n",
    "    neigh = KNeighborsClassifier(n_neighbors=3, metric='mahalanobis', metric_params={'VI' : VI})\n",
    "    neigh.fit(train.get_x(), train.get_y())\n",
    "    y_test, y_pred = test.get_y(), neigh.predict(test.get_x())\n",
    "\n",
    "    accuracy_[i] = (accuracy(y_test, y_pred))\n",
    "    precision_[i] = (precision(y_test, y_pred))\n",
    "    recall_[i] = (recall(y_test, y_pred))\n",
    "    f1_score_[i] = (f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"%i-fold cross validation com %s\" % (n_folds, 'kNN'))\n",
    "print(\"acurácia: %.8f +/- %.8f\" % (accuracy_.mean(), accuracy_.std()))\n",
    "print(\"revocação: %.8f +/- %.8f\" % (precision_.mean(), precision_.std()))\n",
    "print(\"precisão: %.8f +/- %.8f\" % (recall_.mean(), recall_.std()))\n",
    "print(\"f1-score: %.8f +/- %.8f\" % (f1_score_.mean(), f1_score_.std()))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Para cada modelo criado, reporte **valor médio** e **desvio padrão** das métricas de **acurácia**, **revocação**, **precisão** e **F1-score**."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "77ab0bf75426114283fafc7207ca0245f7de4738c2866fb9aad708a7843cc047"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
