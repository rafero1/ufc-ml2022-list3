{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import matplotlib.pyplot as plt  # Biblioteca para gerar gráficos\n",
    "import pandas as pd\n",
    "from sklearn import metrics, model_selection\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Set:\n",
    "    def __init__(self, dataset, features, output):\n",
    "        self.dataset = dataset\n",
    "        self.features = features\n",
    "        self.output = output\n",
    "\n",
    "    def get_n(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def get_x(self):\n",
    "        return self.dataset[:, self.features]\n",
    "    \n",
    "    def get_x_apply(self, func):\n",
    "        return func(self.dataset[:, self.features])\n",
    "\n",
    "    def set_x(self, new_x):\n",
    "        self.x = new_x\n",
    "\n",
    "    def get_y(self):\n",
    "        return self.dataset[:, self.output]\n",
    "\n",
    "    def get_X(self, func=None):\n",
    "        if (func):\n",
    "            return np.c_[np.ones(self.get_n()), func(self.get_x())]\n",
    "        else:\n",
    "            return np.c_[np.ones(self.get_n()), self.get_x()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_true_positive(y, y_pred):\n",
    "    return y_pred >= 1 and y >= 1\n",
    "\n",
    "def is_false_positive(y, y_pred):\n",
    "    return y_pred >= 1 and y <= 0\n",
    "\n",
    "def is_true_negative(y, y_pred):\n",
    "    return y_pred <= 0 and y <= 0\n",
    "\n",
    "def is_false_negative(y, y_pred):\n",
    "    return y_pred <= 0 and y >= 1\n",
    "\n",
    "def confusion_matrix(y, y_pred):\n",
    "    \"\"\" returns (tp, fp, tn, fn) \"\"\"\n",
    "\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for i, pred in enumerate(y_pred):\n",
    "        tp += 1 if is_true_positive(y[i], pred) else 0\n",
    "        fp += 1 if is_false_positive(y[i], pred) else 0\n",
    "        tn += 1 if is_true_negative(y[i], pred) else 0\n",
    "        fn += 1 if is_false_negative(y[i], pred) else 0\n",
    "    return (tp, fp, tn, fn)\n",
    "\n",
    "def accuracy(y, y_pred):\n",
    "    tp, fp, tn, fn = confusion_matrix(y, y_pred)\n",
    "    return (tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "def precision(y, y_pred):\n",
    "    tp, fp, tn, fn = confusion_matrix(y, y_pred)\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(y, y_pred):\n",
    "    tp, fp, tn, fn = confusion_matrix(y, y_pred)\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def f1_score(y, y_pred):\n",
    "    precision_ = precision(y, y_pred)\n",
    "    recall_ = recall(y, y_pred)\n",
    "    return 2 * (precision_ * recall_) / (precision_ + recall_)\n",
    "\n",
    "def get_metrics(n_folds):\n",
    "    return {\n",
    "        \"accuracy\": np.zeros(n_folds),\n",
    "        \"precision\": np.zeros(n_folds),\n",
    "        \"recall\": np.zeros(n_folds),\n",
    "        \"f1_score\": np.zeros(n_folds)\n",
    "    }\n",
    "\n",
    "def calculate_metrics(metrics, y_test, y_pred):\n",
    "    metrics[\"accuracy\"][i] = (accuracy(y_test, y_pred))\n",
    "    metrics[\"precision\"][i] = (precision(y_test, y_pred))\n",
    "    metrics[\"recall\"][i] = (recall(y_test, y_pred))\n",
    "    metrics[\"f1_score\"][i] = (f1_score(y_test, y_pred))\n",
    "\n",
    "def print_metrics(metrics, name, n_folds):\n",
    "    print(\"%i-fold cross validation com %s\" % (n_folds, name))\n",
    "    print(\"acurácia: %.8f +/- %.8f\" % (metrics[\"accuracy\"].mean(), metrics[\"accuracy\"].std()))\n",
    "    print(\"revocação: %.8f +/- %.8f\" % (metrics[\"precision\"].mean(), metrics[\"precision\"].std()))\n",
    "    print(\"precisão: %.8f +/- %.8f\" % (metrics[\"recall\"].mean(), metrics[\"recall\"].std()))\n",
    "    print(\"f1-score: %.8f +/- %.8f\" % (metrics[\"f1_score\"].mean(), metrics[\"f1_score\"].std()))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_split(array, k = int):\n",
    "    \"\"\"realiza o split dos dados em k-folds\"\"\"\n",
    "    shuffled_data = np.random.permutation(array)\n",
    "    folds = np.array_split(shuffled_data, k)\n",
    "    return folds\n",
    "\n",
    "def k_fold_train_test(folds):\n",
    "    \"\"\"retorna um vetor com as configurações de treino e teste definidas pelo k-fold split\n",
    "\n",
    "    returns (i, train, test)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        train = np.vstack([x for j, x in enumerate(folds) if j != i])\n",
    "        test = fold\n",
    "        results.append((i, train, test))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere o conjunto de dados disponível em **kc2.csv**, organizado em 22 colunas, sendo as 21 primeiras colunas os atributos e a última coluna a saída. Os 21 atributos são referentes à caracterização de códigos-fontes para processamento de dados na NASA. A saída é a indicação de ausência (0) ou existência (1) de defeitos. Maiores detalhes sobre os dados p o dem ser conferidos em https://www.openml.org/d/1063."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('kc2.csv', delimiter=',')\n",
    "np.random.seed(666)\n",
    "folds = k_fold_split(data, 10)\n",
    "n_folds = len(folds)\n",
    "features = np.arange(21)\n",
    "output = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Considerando uma validação cruzada em 10 folds, avalie modelos de classificação binária nos dados em questão. Para tanto, use as abordagens abaixo:\n",
    "\n",
    "- **KNN** (escolha k = 1 e k = 5, distância Euclidiana (e Mahalonobis, para a pós-graduação));\n",
    "- **Árvore de decisão** (você pode usar uma implementação já existente com índices de impureza de gini e entropia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(p, q):\n",
    "    return np.abs(np.sqrt(np.sum((p - q)**2)))\n",
    "\n",
    "def cov(X):\n",
    "    mu = np.mean(X, axis=0)\n",
    "    aux = X - mu\n",
    "    return (aux).T.dot(aux) / (X.shape[0])\n",
    "\n",
    "def inverse_cov(X):\n",
    "    cov_ = cov(X)\n",
    "    return np.linalg.pinv(cov_)\n",
    "\n",
    "def mahalanobis_distance(x, u, vi):\n",
    "    \"\"\"vi: inversa da matriz de covariância dos dados de treino\"\"\"\n",
    "    rs = (x - u).T\n",
    "    rs = rs.dot(vi)\n",
    "    rs = rs.dot((x - u))\n",
    "    return np.sqrt(rs)\n",
    "\n",
    "def kNN(X, y, x_test, y_test, k, metric = 'euclidean'):\n",
    "    y_pred = []\n",
    "    vi = inverse_cov(X)\n",
    "\n",
    "    # encontrar k padrões mais próximos\n",
    "    for xi in x_test:\n",
    "        distances = []\n",
    "        for j in range(X.shape[0]):\n",
    "            if metric == 'euclidean':\n",
    "                distances.append(euclidean_distance(xi, X[j, :]))\n",
    "            elif metric == 'mahalanobis':\n",
    "                distances.append(mahalanobis_distance(xi, X[j, :], vi))\n",
    "            else:\n",
    "                distances.append(euclidean_distance(xi, X[j, :]))\n",
    "        distances = np.array(distances)\n",
    "\n",
    "        dist = np.argsort(distances)[:k]\n",
    "        labels = y[dist]\n",
    "\n",
    "        lab = stats.mode(labels) \n",
    "        lab = lab.mode[0]\n",
    "        y_pred.append(lab)\n",
    "\n",
    "    # computar predição com base na ponderação das saidos dos padrões mais próximos\n",
    "    return (y_test, np.array(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Para cada modelo criado, reporte **valor médio** e **desvio padrão** das métricas de **acurácia**, **revocação**, **precisão** e **F1-score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation com kNN (k = 1) - euclidean\n",
      "acurácia: 0.77579826 +/- 0.04814430\n",
      "revocação: 0.45108947 +/- 0.15521950\n",
      "precisão: 0.41541681 +/- 0.15497358\n",
      "f1-score: 0.42191653 +/- 0.13682793\n",
      "\n",
      "10-fold cross validation com kNN (k = 5) - euclidean\n",
      "acurácia: 0.82155298 +/- 0.05290241\n",
      "revocação: 0.58277778 +/- 0.18122823\n",
      "precisão: 0.44840132 +/- 0.22814770\n",
      "f1-score: 0.47842176 +/- 0.18875699\n",
      "\n",
      "10-fold cross validation com kNN (k = 1) - mahalanobis\n",
      "acurácia: 0.79869376 +/- 0.04780905\n",
      "revocação: 0.51771645 +/- 0.14089937\n",
      "precisão: 0.39297591 +/- 0.15838524\n",
      "f1-score: 0.42838302 +/- 0.11797260\n",
      "\n",
      "10-fold cross validation com kNN (k = 5) - mahalanobis\n",
      "acurácia: 0.84092888 +/- 0.05658102\n",
      "revocação: 0.70702381 +/- 0.17814190\n",
      "precisão: 0.40205100 +/- 0.15967510\n",
      "f1-score: 0.49589457 +/- 0.15256657\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    { 'name': 'euclidean', 'k': 1 },\n",
    "    { 'name': 'euclidean', 'k': 5 },\n",
    "    { 'name': 'mahalanobis', 'k': 1 },\n",
    "    { 'name': 'mahalanobis', 'k': 5 },\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model_metrics = get_metrics(n_folds)\n",
    "    for i, train, test in k_fold_train_test(folds):\n",
    "        train = Set(train, features, output)\n",
    "        test = Set(test, features, output)\n",
    "        y_test, y_pred = kNN(train.get_x(), train.get_y(), test.get_x(), test.get_y(), model['k'], model['name'])\n",
    "        calculate_metrics(model_metrics, y_test, y_pred)\n",
    "    print_metrics(model_metrics, \"kNN (k = %s) - %s\" % (model['k'], model['name']), n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation com Decision Trees (gini)\n",
      "acurácia: 0.80446299 +/- 0.04886414\n",
      "revocação: 0.52933761 +/- 0.09637387\n",
      "precisão: 0.50494172 +/- 0.12365909\n",
      "f1-score: 0.50722794 +/- 0.08679636\n",
      "\n",
      "10-fold cross validation com Decision Trees (entropy)\n",
      "acurácia: 0.79303338 +/- 0.04136213\n",
      "revocação: 0.47794594 +/- 0.16782376\n",
      "precisão: 0.48169136 +/- 0.17583641\n",
      "f1-score: 0.47438158 +/- 0.15938129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "criterions = ['gini', 'entropy']\n",
    "\n",
    "for criterion in criterions:\n",
    "    model_metrics = get_metrics(n_folds)\n",
    "    for i, train, test in k_fold_train_test(folds):\n",
    "        train = Set(train, features, output)\n",
    "        test = Set(test, features, output)\n",
    "\n",
    "        tree = DecisionTreeClassifier(criterion=criterion)\n",
    "        tree.fit(train.get_x(), train.get_y())\n",
    "\n",
    "        y_test, y_pred = test.get_y(), tree.predict(test.get_x())\n",
    "        calculate_metrics(model_metrics, y_test, y_pred)\n",
    "    print_metrics(model_metrics, \"Decision Trees (%s)\" % (criterion), n_folds)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "77ab0bf75426114283fafc7207ca0245f7de4738c2866fb9aad708a7843cc047"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
